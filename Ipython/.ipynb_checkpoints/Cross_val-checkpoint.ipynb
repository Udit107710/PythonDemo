{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GridSearchCV\n",
    "In this notebook I will be show you how to GridSearchCV to comapre results from different values of k in KNeighboursClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "We'll be distributing the dataset into label and feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "X = data.data                                   #Feature vector\n",
    "y = data.target                                 #Label vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic way of testing different k values\n",
    "\n",
    "'k' is used for deciding the neighbours the model can take for making clusters in KNeighbourClassifier.\n",
    "To test different values we can repeateadliy create a Classifier and store the results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,31)\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    scores = cross_val_score(knn, X, y, cv = 10, scoring = 'accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "print (k_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('K value of knn')\n",
    "plt.ylabel('Mean score of k value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process of finding the mean and all will be repeated many times thus it is inefficient. Now we will introduce a new function GridSearchCV which will help us in selectng the best tuning parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with GridSearchCV from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = range(1,31)\n",
    "param_grid = dict(n_neighbors = k_range)             #making dictionary of paramerts we want to change\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy', return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X,y)                                        #Using the vectors for fitting the object\n",
    "\n",
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "pan.mean_test_score                             #all the mean test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mean_score = [result for result in grid.cv_results_['mean_test_score']]\n",
    "\n",
    "plt.plot(k_range, grid_mean_score)                    # Graph between diffrent values of 'k' and mean test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)                                  #printing the best combination of parameters based on accuracy\n",
    "print(grid.best_score_)                                   #printing the best score\n",
    "print(grid.best_estimator_)                               #printing the estimator with all the constructor values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
